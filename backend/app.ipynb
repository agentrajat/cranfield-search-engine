{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA6005 Mechanics of Search (2023-2024)<br/>\n",
    "## Assignment 1: Search Engine\n",
    "\n",
    "<b>Student Name:</b> Rajat Jayant Lashkare<br/>\n",
    "<b>Student No:</b> 22267538\n",
    "\n",
    "<br/>\n",
    "The purpose of this notebook is to evaluate following IR Models:\n",
    "\n",
    "1. Vector Space Model\n",
    "2. BM25 Model\n",
    "3. Query Likelyhood with Dirichlet Prior Smoothing Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_system import IRSystem\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing IR System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing IR System\n",
      "Reading documents and queries\n",
      "Found 1400 documents from file.\n",
      "Found 225 queries from file.\n",
      "Building index\n",
      "Indexing... (1400 / 1400)\n",
      "Indexing completed.\n",
      "Initializing retrieval models\n",
      "Calculating TF-IDF for each document...\n",
      "Vector Space Model initialized.\n",
      "BM25 Model initialized.\n",
      "Query Likelyhood Model Initialized.\n",
      "IR System initialized\n"
     ]
    }
   ],
   "source": [
    "ir_system = IRSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what problems of heat conduction in composite slabs have been solved so\n",
      "far .\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['problem', 'heat', 'conduction', 'composite', 'slab', 'solved', 'far']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ir_system.queries[4].title)\n",
    "ir_system.index.process_text(ir_system.queries[4].title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate retrieval models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Space Model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries... (225 / 225)\n",
      "Creating output file...\n",
      "Output file created at ./output/VectorSpaceModel.txt\n",
      "Executing trec_eval for VectorSpaceModel...\n"
     ]
    }
   ],
   "source": [
    "vsm_evaluator = ir_system.evaluate_model(ir_system.get_model(\"vsm\"))\n",
    "vsm_result = ir_system.get_metrics(vsm_evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries... (225 / 225)\n",
      "Creating output file...\n",
      "Output file created at ./output/BM25Model.txt\n",
      "Executing trec_eval for BM25Model...\n"
     ]
    }
   ],
   "source": [
    "bm25_evaluator = ir_system.evaluate_model(ir_system.get_model(\"bm25\"))\n",
    "bm25_result = ir_system.get_metrics(bm25_evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Likelyhood Language Model with Dirichlet Prior Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries... (225 / 225)\n",
      "Creating output file...\n",
      "Output file created at ./output/QueryLikelyhoodDPSModel.txt\n",
      "Executing trec_eval for QueryLikelyhoodDPSModel...\n"
     ]
    }
   ],
   "source": [
    "ql_evaluator = ir_system.evaluate_model(ir_system.get_model(\"qldps\"))\n",
    "ql_result = ir_system.get_metrics(ql_evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|Evaluation metrics|VSM|BM25|QueryLM|\n",
       "|---|---|---|---|\n",
       "|map|0.2807|0.3119|0.2871|\n",
       "|P_5|0.2933|0.3324|0.296|\n",
       "|ndcg|0.5315|0.5567|0.5378|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_md_cmpare(result1, result2, result3):\n",
    "    md = \"|Evaluation metrics|VSM|BM25|QueryLM|\\n|---|---|---|---|\\n\"\n",
    "    for key, value in result1.items():\n",
    "        md += f\"|{key}|{value}|{result2[key]}|{result3[key]}|\\n\"\n",
    "    display(Markdown(md))\n",
    "to_md_cmpare(vsm_result, bm25_result, ql_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|Evaluation metrics|VSM|BM25|QueryLM|\n",
       "|---|---|---|---|\n",
       "|map|0.2977|0.3119|0.2871|\n",
       "|P_5|0.3102|0.3324|0.296|\n",
       "|ndcg|0.5439|0.5567|0.5378|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_md_cmpare(result1, result2, result3):\n",
    "    md = \"|Evaluation metrics|VSM|BM25|QueryLM|\\n|---|---|---|---|\\n\"\n",
    "    for key, value in result1.items():\n",
    "        md += f\"|{key}|{value}|{result2[key]}|{result3[key]}|\\n\"\n",
    "    display(Markdown(md))\n",
    "to_md_cmpare(vsm_result, bm25_result, ql_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca683",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
